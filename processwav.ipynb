{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ae3fa-a5f7-4060-8557-fd72e0013e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f716974-88fa-4aea-8048-776e5bc03e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#wget https://github.com/libsndfile/libsndfile/releases/download/1.1.0/libsndfile-1.1.0.tar.xz\n",
    "import urllib.request\n",
    "url = 'https://github.com/libsndfile/libsndfile/releases/download/1.1.0/libsndfile-1.1.0.tar.xz'\n",
    "filename = 'libsndfile-1.1.0.tar.xz'\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "!tar -xf libsndfile-1.1.0.tar.xz\n",
    "! (cd ./libsndfile-1.1.0/ && ./configure && make && make install)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029e6b7d-744c-4a7b-8594-1b13052cf7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "0.12.1+cu113\n",
      "0.13.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c08d6-4fa6-4fa9-aee4-f549827281e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f9ddd-8aa0-4daa-b93d-738db6647b12",
   "metadata": {},
   "source": [
    "# Prepare data for the Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c6b81-90a0-413d-95bb-2b53059dc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run run.py -m train -ct -w 0.7 -s 0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eee7d1-d5de-43be-afee-8ddd6461a75a",
   "metadata": {},
   "source": [
    "# Preparing data for validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f167d-0246-4fee-aa06-1b069bb9462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run run.py -m val -ct -w 0.7 -s 0.08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1181cd88-b277-4e2b-ab7f-84991df029d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test the data generation process for a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d7ffb-0dff-4469-bd1c-724c65d1598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run-singlefile.py -f ./testwav/nextel.wav -od ./outputsinglewav -sr 16000 -ct -w 0.7 -s 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889fc817-0cec-4bf6-a22f-41f67057d9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import audioprocess as AP\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import tensor_util as TU\n",
    "import queue\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import torchaudio.functional as F\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BeepDetectDataset(Dataset):\n",
    "\n",
    "    def __init__(self, annotations_file,transformation,target_sample_rate,plot,debug):\n",
    "        pd.options.display.max_seq_items = 2000\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.transformation = transformation\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.plot = plot\n",
    "        self.debug = debug\n",
    "        self.smax = 0\n",
    "        self.fmax = 0\n",
    "        self.smin = 0\n",
    "        self.fmin = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = self._resample_if_necessary(signal, self.target_sample_rate)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        \n",
    "        #adding noise\n",
    "        #noise, signal = AP.preprocess_wav(signal,self.target_sample_rate,2)\n",
    "        \n",
    "        self.smax = (torch.max(signal))\n",
    "        self.smin = (torch.min(signal))\n",
    "        \n",
    "        if  self.debug: \n",
    "            print(f'audio_sample_path {audio_sample_path} label {label}' )\n",
    "            print (f' S Max {self.smax} S Min {self.smin}')\n",
    "\n",
    "        if  self.plot:\n",
    "            AP.plot_waveform(signal,self.target_sample_rate)\n",
    "            #noise, newwav = AP.preprocess_wav(signal,self.target_sample_rate)\n",
    "            #AP.plot_waveform(newwav,self.target_sample_rate)\n",
    "        #signal = torch.round(signal, decimals=2) \n",
    "        \n",
    "        if self.smax < 0.01 and self.smin > -0.01 :\n",
    "                #print (signal)\n",
    "                signal = signal.clone()\n",
    "                signal[torch.logical_and(signal>=-0.01, signal<=0.01)] = 0\n",
    "                #print (signal)\n",
    "                \n",
    "        \n",
    "        signal = self.transformation(signal)\n",
    "        \n",
    "        self.fmax = (torch.max(signal))\n",
    "        self.fmin = (torch.min(signal))\n",
    "        signal = torch.round(signal, decimals=1)\n",
    "        \n",
    "        signal = signal.clone()\n",
    "        \n",
    "        #signal[torch.logical_and(signal>=0, signal<=1e-1)] = 1e-4 \n",
    "        \n",
    "        if signal.min() != signal.max():\n",
    "        \n",
    "            signal -= signal.min()\n",
    "            signal /= signal.max()\n",
    "        \n",
    "        #signal = signal.log2()\n",
    "        \n",
    "        #self.fmax = (torch.max(signal))\n",
    "        #self.fmin = (torch.min(signal))\n",
    "        \n",
    "        if self.debug:\n",
    "            print (f' F Max {self.fmax} F Min {self.fmin}')\n",
    "        if self.plot:\n",
    "            print(f'SHAPE SIGNAL {signal.shape}')\n",
    "            AP.plot_spectrogram(signal)\n",
    "        preprocessedsignal = signal\n",
    "        #print (signal.shape)\n",
    "        signal = signal.repeat(3, 1, 1) \n",
    "        \n",
    "        signal = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(signal)\n",
    "        \n",
    "        #print (signal.shape)\n",
    "        return signal,preprocessedsignal, label, audio_sample_path,sr,self.fmin,self.fmax,self.smin,self.smax\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = self.annotations.iloc[index, 1]\n",
    "        return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        label= self.annotations.iloc[index, 2]\n",
    "        if label:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "        return label\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        #if signal.shape[0] > 1:\n",
    "        #    signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "def create_data_loader(train_data, batch_size,shaf=True):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size,shuffle=shaf)\n",
    "    return train_dataloader\n",
    "\n",
    "\n",
    "def train_single_epoch(model, data_loader, loss_fn, optimiser, device,ep,debug=False,evalu=False):\n",
    "    lenght = len(data_loader.dataset)\n",
    "    piv = 0\n",
    "    piv_t=0\n",
    "    n=0\n",
    "    n0=0\n",
    "    n1=0\n",
    "    nsp0=0\n",
    "    nsp1 = 0\n",
    "            \n",
    "    for input, preprocessedsignal, target, audio_sample_path,sr,fmin,fmax,smin,smax in data_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        datasize = target.size(dim=0)\n",
    "        piv = piv + datasize\n",
    "        per = round(piv / lenght * 100) \n",
    "        #print (input.shape)\n",
    "        #print (target)\n",
    "        # calculate loss\n",
    "        prediction = model(input)\n",
    "        _, predicted = torch.max(prediction, 1)\n",
    "        loss = loss_fn(prediction, target)\n",
    "                \n",
    "        for dt in range(datasize):\n",
    "            targetint = int (target[dt].int())\n",
    "            predictedint = int (predicted[dt].int())\n",
    "\n",
    "            if targetint == 1:\n",
    "                n1=n1+1\n",
    "                if predictedint == 1:\n",
    "                    nsp1=nsp1+1\n",
    "            elif targetint == 0:\n",
    "                n0=n0+1\n",
    "                if predictedint == 0:\n",
    "                    nsp0=nsp0+1       \n",
    "\n",
    "        # backpropagate error and update weights\n",
    "        if evalu == False:\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        print (f'\\r v1 epoch {ep} - {per}% loss {loss} -- fmin {torch.min(fmin)} fmax {torch.max(fmax)} smin {torch.min(smin)} smax {torch.max(smax)}', end=\"\")\n",
    "        #print (f'\\r n0 {n0} n1 {n1} nsp0 {nsp0} nsp1 {nsp1} n {piv}',end=\"\")\n",
    "\n",
    "    print(f\"\\rloss: {loss.item()}\")\n",
    "    return  piv,n0,n1,nsp0,nsp1\n",
    "\n",
    "\n",
    "def train(model, data_loader, loss_fn, optimiser, device, epochs,debug=False,evalu=False,useckp=True):\n",
    "    n=0\n",
    "    n0=0\n",
    "    n1=0\n",
    "    nsp0=0\n",
    "    nsp1=0\n",
    "    dtstart = datetime.now()\n",
    "    lowestloss = 100000\n",
    "    #overalloss = 0\n",
    "    epochloss=[]\n",
    "    start_epoch=1\n",
    "    print (\"Starting Training\")\n",
    "    \n",
    "    if useckp:\n",
    "        if os.path.isfile(\"./checkpoint/checkpoint.pt\"):\n",
    "            model, optimiser, start_epoch, lowestloss,epochloss,n0,n1,nsp0,nsp1,n = load_ckp(model, optimiser)\n",
    "            #lowestloss = ((n0-nsp0)+(n1-nsp1))/(n0+n1)\n",
    "            print(f\"Loading checkpoint start epoch {start_epoch}, lowestloss {lowestloss}, n0 {n0}, n1 {n1}, nsp0 {nsp0}, nsp1 {nsp1},n {n}\")\n",
    "            start_epoch=start_epoch+1\n",
    "        else:\n",
    "            print (\"NO CHECK POINT FILE ..SKIPPING\")\n",
    "    if evalu == True:\n",
    "            print(f'Evaluation mode')\n",
    "            model.eval()\n",
    "    else:\n",
    "            model.train()\n",
    "    \n",
    "    for i in range(start_epoch,epochs):\n",
    "        print(f\"Epoch {i}\")\n",
    "        dtepochstart = datetime.now()\n",
    "\n",
    "        n,n0,n1,nsp0,nsp1 = train_single_epoch(model, data_loader, loss_fn, optimiser, device, i,debug,evalu)\n",
    "        print(\"---------------------------\")\n",
    "        # save model\n",
    "        overalloss = ((n0-nsp0)+(n1-nsp1))/(n0+n1)\n",
    "        dtepochstop = datetime.now()\n",
    "        epochloss.append(overalloss)\n",
    "        #checkpoint={}\n",
    "        checkpoint = {\n",
    "        'epoch': i,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimiser.state_dict(),\n",
    "        'loss': overalloss, \n",
    "        'epochloss': epochloss,\n",
    "        'n0': n0, \n",
    "        'n1': n1, \n",
    "        'nsp0': nsp0,\n",
    "        'nsp1': nsp1,\n",
    "        'n': n\n",
    "        }\n",
    "        print (\"epoch lossess trend:\",epochloss)\n",
    "        if (evalu == False) and (overalloss < lowestloss):\n",
    "            print (f'Overall loss {overalloss} < lowestloss {lowestloss} saving {STD_MODEL_WEIGHTS_BEST}')\n",
    "            torch.save(model.state_dict(), STD_MODEL_WEIGHTS_BEST)\n",
    "            save_ckp('./checkpoint/checkpoint_'+str(i)+'_'+str(overalloss)+'.pt',checkpoint)\n",
    "            lowestloss = overalloss\n",
    "        print (f'Overall loss {overalloss} n0 {n0} n1 {n1} nsp0 {nsp0} nsp1 {nsp1} n {n} time {dtepochstop-dtepochstart}')\n",
    "\n",
    "        if (evalu == False) and (i%5 == 0):\n",
    "            torch.save(model.state_dict(), STD_MODEL_WEIGHTS)\n",
    "            print(\"Net saved at feedforwardnet.pth\")\n",
    "        \n",
    "        checkpoint = {\n",
    "        'epoch': i,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimiser.state_dict(),\n",
    "        'loss': lowestloss, \n",
    "        'epochloss': epochloss,\n",
    "        'n0': n0, \n",
    "        'n1': n1, \n",
    "        'nsp0': nsp0,\n",
    "        'nsp1': nsp1,\n",
    "        'n': n\n",
    "        }    \n",
    "        \n",
    "        print(\"Saving ./checkpoint/checkpoint.pt\")\n",
    "        save_ckp('./checkpoint/checkpoint.pt',checkpoint)\n",
    "    \n",
    "    dtstop = datetime.now()      \n",
    "    print(f'Finished training in {dtstop-dtstart}')\n",
    "\n",
    "def validate_model(model,data_loader,loss_fn,device,debug):\n",
    "      train(model, data_loader, loss_fn, None , device,1,debug,True)\n",
    "        \n",
    "def predict(model, input, expected):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input)\n",
    "        _, predicted = torch.max(prediction, 1) \n",
    "        predictedsoft = torch.softmax(prediction,1)\n",
    "        #predictedsoft = predicted\n",
    "    return predicted, expected ,predictedsoft\n",
    "\n",
    "\n",
    "def countvaluesinwin(slwin):\n",
    "    count = 0\n",
    "    slwinc = queue.Queue() \n",
    "    slwinc.queue = copy.deepcopy(slwin.queue)\n",
    "    \n",
    "    while not slwinc.empty():\n",
    "        value = slwinc.get() \n",
    "        #print(\"value\",value)\n",
    "        if value == 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def scanfileforbeep(values):\n",
    "    slidingwin = queue.Queue()\n",
    "    countof0 = 0\n",
    "    piv = 0\n",
    "    beepdetected = False\n",
    "    start = True\n",
    "\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    \n",
    "    isthereabeep = False\n",
    "    \n",
    "    for va in values:\n",
    "        rem = slidingwin.get(False)\n",
    "        slidingwin.put(va)\n",
    "        \n",
    "        countof0 = countvaluesinwin(slidingwin)\n",
    "        if countof0 > 3:\n",
    "                beepdetected = True\n",
    "                isthereabeep = True\n",
    "        else:\n",
    "                beepdetected = False\n",
    "        #print(va,countof0,beepdetected)\n",
    "\n",
    "    return isthereabeep\n",
    "\n",
    "def resample_if_necessary(signal,target_sample_rate, sr):\n",
    "        if sr != target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "def mix_down_if_necessary(signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "def getfinalsignal(wavetensor,samplerate,transformation,debug,plot):\n",
    "        \n",
    "        signal = resample_if_necessary(wavetensor,samplerate,samplerate)\n",
    "        signal = mix_down_if_necessary(signal)\n",
    "\n",
    "        smax = (torch.max(signal))\n",
    "        smin = (torch.min(signal))\n",
    "\n",
    "        if  debug: \n",
    "            print(f'samplerate {samplerate}' )\n",
    "            print (f' S Max {smax} S Min {smin}')\n",
    "\n",
    "        if smax < 0.01 and smin > -0.01 :\n",
    "                #print (signal)\n",
    "                signal = signal.clone()\n",
    "                signal[torch.logical_and(signal>=-0.01, signal<=0.01)] = 0\n",
    "                #print (signal)\n",
    "        if  plot:\n",
    "            AP.plot_waveform(signal,samplerate)\n",
    "        \n",
    "        ns,wav = AP.preprocess_wav(signal,samplerate,2)\n",
    "        pitch = F.detect_pitch_frequency(wav, samplerate)\n",
    "        \n",
    "        if  plot:\n",
    "            AP.plot_waveform(wav,samplerate)\n",
    "            AP.plot_waveform(pitch,samplerate)\n",
    "\n",
    "        \n",
    "        #signal = torch.round(signal, decimals=2) \n",
    "        \n",
    "            \n",
    "        signal = transformation(wav)\n",
    "\n",
    "        fmax = (torch.max(signal))\n",
    "        fmin = (torch.min(signal))\n",
    "        signal = torch.round(signal, decimals=1)\n",
    "        \n",
    "        #signal = round(signal,1)\n",
    "        #signal[signal < 200] = 0\n",
    "        \n",
    "        signal = signal.clone()\n",
    "\n",
    "        #signal[torch.logical_and(signal>=0, signal<=1e-1)] = 1e-4 \n",
    "\n",
    "        if signal.min() != signal.max():\n",
    "\n",
    "            signal -= signal.min()\n",
    "            signal /= signal.max()\n",
    "        \n",
    "        #if  plot:\n",
    "        #    AP.plot_waveform(signal,samplerate)\n",
    "        #signal = signal.log2()\n",
    "\n",
    "        #self.fmax = (torch.max(signal))\n",
    "        #self.fmin = (torch.min(signal))\n",
    "\n",
    "        if debug:\n",
    "            print (f' F Max {fmax} F Min {fmin}')\n",
    "        if plot:\n",
    "            print(f'SHAPE SIGNAL {signal.shape}')\n",
    "            AP.plot_spectrogram(signal)\n",
    "        preprocessedsignal = signal\n",
    "        #print (signal.shape)\n",
    "        signal = signal.repeat(3, 1, 1) \n",
    "        signal = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(signal)\n",
    "        signal = signal[None]\n",
    "        #print (signal.shape)\n",
    "        return signal\n",
    "\n",
    "def preparedata (filename,samplerate,transformation,debug,plot):\n",
    "            signal, sr = torchaudio.load(filename)\n",
    "            return getfinalsignal(signal,samplerate,transformation,debug,plot)\n",
    "\n",
    "def doeswavhavebeep(outputdir):\n",
    "        annotations = pd.read_csv(outputdir+\"/wavlist.csv\")\n",
    "        files = annotations['slices'].tolist()\n",
    "        li = []\n",
    "        for file in files:\n",
    "            res = preparedata (file,16000,transform_spectra,False,False)\n",
    "            predicted, expected,predictedsoft = predict(new_model_pred,res,0)\n",
    "            predicted = int(predicted.int())\n",
    "            print(f'file {file} predicted {predicted}')\n",
    "            li.append(predicted)\n",
    "        return scanfileforbeep(li)\n",
    "\n",
    "def scan_file_for_beep(model,device,file,window,stride,targetsamplerate,debug1,debug,plot,retimmediately=False):\n",
    "    \n",
    "    #print(f'Processing file {file} window {window} stride {stride} ')\n",
    "\n",
    "    waveformpre, sample_rate, duration = AP.load_audio_from_file(file)\n",
    "    #print(f'sample_rate {sample_rate} duration {duration}')\n",
    "    waveformpre, sample_rate = AP.resample_wav_plus_mono(waveformpre,sample_rate,targetsamplerate)\n",
    "    #print(f'sample_rate {sample_rate}')\n",
    "\n",
    "    realshift = 0\n",
    "\n",
    "    waveform = TU.sub_from_begin_2nd_tensor(waveformpre,realshift)\n",
    "    slices,number = AP.slice_the_audio_w_0_pad(waveform,sample_rate,window,stride)\n",
    "    \n",
    "    #print(f'Generated {number} slices')\n",
    "    \n",
    "    tslices = []\n",
    "\n",
    "    slidingwin = queue.Queue()\n",
    "\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    slidingwin.put(1)\n",
    "    \n",
    "    istherebeep = False\n",
    "    timeofbeep = -1\n",
    "    \n",
    "    dtstart = datetime.now()\n",
    "    \n",
    "    for i in range (number):\n",
    "        wavtensor = slices.select(1,i)\n",
    "        #tslices.append(wavtensor)\n",
    "        signal = getfinalsignal(wavtensor,targetsamplerate,transform_spectra,debug,plot)\n",
    "        signal = signal.to(device)\n",
    "        predicted, expected,predictedsoft = predict(model,signal,0)\n",
    "        predicted = int(predicted.int())\n",
    "        \n",
    "        win = window*targetsamplerate\n",
    "        st = stride*targetsamplerate\n",
    "        \n",
    "        fwin = win+st*i\n",
    "        time = fwin/targetsamplerate\n",
    "        \n",
    "        rem = slidingwin.get(False)\n",
    "        slidingwin.put(predicted)\n",
    "        countof0 = countvaluesinwin(slidingwin)\n",
    "        if countof0 > 3:\n",
    "            istherebeep = True\n",
    "            if timeofbeep == -1:\n",
    "                timeofbeep = time\n",
    "                if retimmediately:\n",
    "                    return istherebeep, timeofbeep\n",
    "                else:\n",
    "                    istherebeep= False\n",
    "                    \n",
    "        if debug1:\n",
    "            print (f'slice {i} beepinwindow {predicted==0} beepfound {istherebeep} time {time} timeofbeep {timeofbeep}' )\n",
    "    \n",
    "    dtstop = datetime.now()\n",
    "    if retimmediately == False:\n",
    "        AP.plot_waveform_withline(waveformpre,sample_rate,timeofbeep,\"beep\")\n",
    "    if debug1:\n",
    "        print(f'Processing Start {dtstart} Stop {dtstop} duration {dtstop-dtstart}')\n",
    "    return istherebeep, timeofbeep\n",
    "\n",
    "'''\n",
    "def round(x, decimals=0):\n",
    "    b = 10**decimals\n",
    "    return torch.round(x*b)/b\n",
    "'''\n",
    "\n",
    "def save_ckp(f_path,state):\n",
    "    torch.save(state, f_path)\n",
    "\n",
    "def load_ckp(model, optimizer):\n",
    "    f_path = './checkpoint/checkpoint.pt'\n",
    "    checkpoint = torch.load(f_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'],checkpoint['loss'],checkpoint['epochloss'],checkpoint['n0'],checkpoint['n1'],checkpoint['nsp0'],checkpoint['nsp1'],checkpoint['n']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc30d28-d28b-4b8b-b21f-df8893038bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet152(pretrained=True)\n",
    "        # Replace last layer\n",
    "        #for param in self.network.parameters():\n",
    "        #    param.requires_grad = False\n",
    "        self.network.conv1=nn.Conv2d(1, self.network.conv1.out_channels, \n",
    "                      kernel_size=self.network.conv1.kernel_size[0], \n",
    "                      stride=self.network.conv1.stride[0], \n",
    "                      padding=self.network.conv1.padding[0])\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, 2)\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    def freeze(self):\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = False\n",
    "        for param in self.network.fc.parameters():\n",
    "            param.require_grad = True\n",
    "    def unfreeze(self):\n",
    "        for param in self.network.parameters():\n",
    "            param.require_grad = True\n",
    "\n",
    "class Net2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet34(pretrained=False)\n",
    "        # Replace last layer\n",
    "        #for param in self.network.parameters():\n",
    "        #    param.requires_grad = False\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, 2)\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    \n",
    "def _freeze_norm_stats(net):\n",
    "    try:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                #m.track_running_stats = False\n",
    "                m.train()\n",
    "\n",
    "    except ValueError:  \n",
    "        print(\"errrrrrrrrrrrrrroooooooorrrrrrrrrrrr with instancenorm\")\n",
    "        return\n",
    "    \n",
    "def _set_batch_momentum(net,mom):\n",
    "    try:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.momentum = mom\n",
    "                #m.train()\n",
    "\n",
    "    except ValueError:  \n",
    "        print(\"errrrrrrrrrrrrrroooooooorrrrrrrrrrrr with instancenorm\")\n",
    "        return\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17460f2c-42d8-4ff1-8bfd-87d773c247ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 600\n",
    "LEARNING_RATE = 0.01\n",
    "ANNOTATIONS_FILE = \"./outputpretrainwav/wavlist.csv\"\n",
    "VALIDATION_FILE = \"./outputpretrainwav_val/wavlist.csv\"\n",
    "SAMPLE_RATE=16000\n",
    "size=224\n",
    "STD_MODEL_WEIGHTS=\"feedforwardnet-temp.pth\"\n",
    "STD_MODEL_WEIGHTS_BEST='feedforwardnet-best.pth'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "#device=\"cpu\"\n",
    "# instantiating our dataset object and create data loader\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    win_length = 2048,\n",
    "    n_fft=2048,\n",
    "    hop_length=256,\n",
    "    n_mels=128,\n",
    "    f_max=4500,\n",
    "    f_min=200,\n",
    "    normalized = False\n",
    ")\n",
    "\n",
    "\n",
    "transform_spectra = T.Compose([\n",
    "    mel_spectrogram,\n",
    "    T.Resize((size,size)),\n",
    "])\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307aada-d674-4487-a407-3efeec079324",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638c975-c6fc-4b8a-a4f4-435ea83320e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "NO CHECK POINT FILE ..SKIPPING\n",
      "Epoch 1\n",
      "[2024-01-21 11:28:25.837 pytorch-1-12-gpu-py-ml-g4dn-xlarge-fb2c43dabd38fe5c0df5e678313a:67 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-01-21 11:28:26.020 pytorch-1-12-gpu-py-ml-g4dn-xlarge-fb2c43dabd38fe5c0df5e678313a:67 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg/smdebug/profiler/system_metrics_reader.py:78: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " v1 epoch 1 - 34% loss 0.000825898430775851 -- fmin 0.0008494672947563231 fmax 1146.7117919921875 smin -0.20026475191116333 smax 0.310861945152282730273"
     ]
    }
   ],
   "source": [
    "usd = BeepDetectDataset(ANNOTATIONS_FILE,\n",
    "                        transform_spectra,\n",
    "                        SAMPLE_RATE,False,False)\n",
    "\n",
    "train_dataloader = create_data_loader(usd, BATCH_SIZE)\n",
    "model_ft = Net2()\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "_set_batch_momentum(model_ft,0.9)\n",
    "\n",
    "\n",
    "# initialise loss funtion + optimiser\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss_fn = nn.BCELoss()\n",
    "optimiser = torch.optim.Adam(model_ft.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "#optimiser = torch.optim.SGD(model_ft.parameters(),lr=LEARNING_RATE,momentum=0.9)\n",
    "# train model\n",
    "train(model_ft, train_dataloader, loss_fn, optimiser, device, EPOCHS)\n",
    "\n",
    "# save model\n",
    "torch.save(model_ft.state_dict(), STD_MODEL_WEIGHTS)\n",
    "print(\"Trained feed forward net saved at feedforwardnet.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa99f7f-0713-4270-8de5-fa993eaa57ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44112e65-9c8c-4315-bc9b-3c4cf696b9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALIDATION_FILE = \"./outputpretrainwav_val/wavlist.csv\"\n",
    "mod_w= STD_MODEL_WEIGHTS_BEST\n",
    "state_dict = torch.load(mod_w)\n",
    "model_val = Net2().to(device)\n",
    "model_val.load_state_dict(state_dict)\n",
    "\n",
    "usdval = BeepDetectDataset(VALIDATION_FILE,\n",
    "                        transform_spectra,\n",
    "                        SAMPLE_RATE,False,False)\n",
    "\n",
    "val_dataloader = create_data_loader(usdval,1)\n",
    "validate_model(model_val, val_dataloader,loss_fn, device,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee51ade-b264-4ec0-98f5-955b8c4d3e27",
   "metadata": {},
   "source": [
    "The following cell will iterate the CSV file and loops through each FILE in search of a beep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b490ef4e-57e5-4c75-849c-9b1beeae40bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e00967-7da2-4dd5-aacf-f2fc9909cf2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LOADING STATE\n",
      "Model READY\n",
      "File ./testwav/machine-tape-035a.wav isbeep False predicted time -1 expected -1\n",
      "File ./testwav/nextel.wav isbeep True predicted time 11.34 expected 11.021\n",
      "File ./testwav/sprint.wav isbeep True predicted time 20.94 expected 20.690\n",
      "File ./testwav/verizon.wav isbeep True predicted time 20.86 expected 20.600\n",
      "Test run SUCCEDED\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "model_weights =STD_MODEL_WEIGHTS_BEST\n",
    "\n",
    "new_state_dict = torch.load(model_weights)\n",
    "\n",
    "new_model_pred= Net2().to(device)\n",
    "new_model_pred.load_state_dict(new_state_dict)\n",
    "\n",
    "print(\"Model LOADING STATE\")\n",
    "\n",
    "files = {\n",
    "        './testwav/machine-tape-035a.wav':'-1',\n",
    "        './testwav/nextel.wav':'11.021',\n",
    "        './testwav/sprint.wav':'20.690',\n",
    "        './testwav/verizon.wav':'20.600'\n",
    "         }\n",
    "         \n",
    "\n",
    "debug=False\n",
    "single=False\n",
    "new_model_pred.eval()\n",
    "_freeze_norm_stats(new_model_pred)\n",
    "\n",
    "print(\"Model READY\")\n",
    "\n",
    "count_faild=0\n",
    "failed_files=[]\n",
    "\n",
    "if single:\n",
    "    isabeep, time = scan_file_for_beep(new_model_pred,device,File_name,0.7,0.08,16000,True,debug,debug,False)   \n",
    "    print (f'File {File_name} isbeep {isabeep} predicted time {time}') \n",
    "else:\n",
    "    tests = files.keys()\n",
    "    for f in tests:\n",
    "        File_name=f\n",
    "        #isabeep, time = scan_file_for_beep(new_model_pred,File_name,1,0.15,16000,False,debug,debug,True)   \n",
    "        isabeep, time = scan_file_for_beep(new_model_pred,device,File_name,0.7,0.08,16000,False,debug,False,True)   \n",
    "        \n",
    "        timediff=abs(float(time)-float(files[f]))\n",
    "        \n",
    "        if timediff > 0.08*4:\n",
    "            count_faild=count_faild+1\n",
    "            failed_files.append(File_name)\n",
    "        print (f'File {File_name} isbeep {isabeep} predicted time {time} expected {files[f]}') \n",
    "    if count_faild > 0:\n",
    "        print(\"Test run FAILED - n of TC failed & filenames\",count_faild,failed_files)\n",
    "    else:\n",
    "        print(\"Test run SUCCEDED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b463e9-8072-48b8-9791-8fd903d22690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(model, optimizer):\n",
    "    f_path = './checkpoint/checkpoint.pt'\n",
    "    checkpoint = torch.load(f_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch'],checkpoint['loss'],checkpoint['epochloss'],checkpoint['n0'],checkpoint['n1'],checkpoint['nsp0'],checkpoint['nsp1'],checkpoint['n']\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.12 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/pytorch-1.12-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
